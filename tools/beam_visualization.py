"""
æŸæµæ³¢åŠ¨åˆ†æç»“æœå¯è§†åŒ–å·¥å…·
ç”¨è‡ªç„¶è¯­è¨€æ•´ç†åˆ†æç»“æœï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥ PLS åˆ†æå·¥å…·
try:
    from .pls_analysis import PLSAnalysisTool
    from .data_query import DataQueryTool
except ImportError:
    import sys
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)
    from tools.pls_analysis import PLSAnalysisTool
    from tools.data_query import DataQueryTool


class BeamVisualizationTool:
    """æŸæµæ³¢åŠ¨åˆ†æå¯è§†åŒ–å·¥å…·ç±»"""
    
    def __init__(self, model_path: Optional[str] = None, data_path: Optional[str] = None):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
        
        Args:
            model_path: PLS æ¨¡å‹æ–‡ä»¶è·¯å¾„
            data_path: CSVæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.pls_tool = PLSAnalysisTool(model_path=model_path, data_path=data_path)
        self.data_path = self.pls_tool.data_path
    
    def format_analysis_result(self, analysis_result: Dict[str, Any]) -> str:
        """
        å°†åˆ†æç»“æœæ ¼å¼åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°
        
        Args:
            analysis_result: analyze_beam_fluctuation å‡½æ•°çš„è¿”å›ç»“æœ
        
        Returns:
            æ ¼å¼åŒ–åçš„è‡ªç„¶è¯­è¨€æè¿°æ–‡æœ¬
        """
        if not analysis_result.get('success', False):
            return f"âŒ åˆ†æå¤±è´¥ï¼š{analysis_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
        
        lines = []
        lines.append("=" * 70)
        lines.append("ğŸ“Š æŸæµæ³¢åŠ¨åˆ†ææŠ¥å‘Š")
        lines.append("=" * 70)
        
        # 1. åŸºæœ¬ä¿¡æ¯
        lines.append("\nã€åˆ†ææ—¶é—´èŒƒå›´ã€‘")
        lines.append(f"  èµ·å§‹æ—¶é—´ï¼š{analysis_result['start_time']}")
        lines.append(f"  ç»“æŸæ—¶é—´ï¼š{analysis_result['end_time']}")
        lines.append(f"  æ•°æ®æ¡æ•°ï¼š{analysis_result['data_count']} æ¡")
        
        # 2. ç»Ÿè®¡ä¿¡æ¯
        lines.append("\nã€ç»Ÿè®¡æŒ‡æ ‡ã€‘")
        stats = analysis_result['statistics']
        thresholds = analysis_result['thresholds']
        
        lines.append(f"  TÂ²ç»Ÿè®¡é‡ï¼š")
        lines.append(f"    - å‡å€¼ï¼š{stats['T2X_mean']:.4f}")
        lines.append(f"    - æœ€å¤§å€¼ï¼š{stats['T2X_max']:.4f}")
        lines.append(f"    - æœ€å°å€¼ï¼š{stats['T2X_min']:.4f}")
        lines.append(f"    - æ ‡å‡†å·®ï¼š{stats['T2X_std']:.4f}")
        lines.append(f"    - æ§åˆ¶ä¸Šé™ (UCL)ï¼š{thresholds['UCL_T2X']:.4f}")
        
        lines.append(f"\n  SPEç»Ÿè®¡é‡ï¼š")
        lines.append(f"    - å‡å€¼ï¼š{stats['SPEX_mean']:.4f}")
        lines.append(f"    - æœ€å¤§å€¼ï¼š{stats['SPEX_max']:.4f}")
        lines.append(f"    - æœ€å°å€¼ï¼š{stats['SPEX_min']:.4f}")
        lines.append(f"    - æ ‡å‡†å·®ï¼š{stats['SPEX_std']:.4f}")
        lines.append(f"    - æ§åˆ¶ä¸Šé™ (UCL)ï¼š{thresholds['UCL_SPEX']:.4f}")
        
        # 3. å¼‚å¸¸æ£€æµ‹ç»“æœ
        lines.append("\nã€å¼‚å¸¸æ£€æµ‹ç»“æœã€‘")
        anomaly = analysis_result['anomaly_detection']
        summary = analysis_result['summary']
        
        status_emoji = "âœ…" if not summary['has_anomaly'] else "âš ï¸"
        lines.append(f"  çŠ¶æ€ï¼š{status_emoji} {summary['status']}")
        lines.append(f"  æ€»æ ·æœ¬æ•°ï¼š{anomaly['total_samples']} ä¸ª")
        lines.append(f"  å¼‚å¸¸ç‚¹æ•°ï¼š{anomaly['anomaly_count']} ä¸ª")
        lines.append(f"  å¼‚å¸¸ç‡ï¼š{anomaly['anomaly_rate']:.2%}")
        lines.append(f"  TÂ²å¼‚å¸¸æ•°ï¼š{anomaly['T2X_anomaly_count']} ä¸ª")
        lines.append(f"  SPEå¼‚å¸¸æ•°ï¼š{anomaly['SPEX_anomaly_count']} ä¸ª")
        
        # 4. ç»“è®ºæ€§æè¿°
        lines.append("\nã€åˆ†æç»“è®ºã€‘")
        if not summary['has_anomaly']:
            lines.append("  âœ“ è¯¥æ—¶é—´æ®µå†…æŸæµè¿è¡ŒçŠ¶å†µè‰¯å¥½ï¼Œæ‰€æœ‰æ•°æ®ç‚¹å‡åœ¨æ­£å¸¸èŒƒå›´å†…ã€‚")
            lines.append("  âœ“ TÂ²ç»Ÿè®¡é‡å’ŒSPEç»Ÿè®¡é‡å‡æœªè¶…å‡ºæ§åˆ¶ä¸Šé™ã€‚")
            lines.append("  âœ“ æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„å¼‚å¸¸æ³¢åŠ¨ã€‚")
        else:
            lines.append(f"  âš  è¯¥æ—¶é—´æ®µå†…æ£€æµ‹åˆ° {anomaly['anomaly_count']} ä¸ªå¼‚å¸¸ç‚¹ã€‚")
            lines.append(f"  âš  å¼‚å¸¸ç‡ä¸º {anomaly['anomaly_rate']:.2%}ï¼Œéœ€è¦å…³æ³¨ã€‚")
            
            # è¯¦ç»†åˆ†æç¬¬ä¸€ä¸ªå¼‚å¸¸ç‚¹
            first_anomaly = anomaly.get('first_anomaly')
            if first_anomaly:
                lines.append("\nã€é¦–ä¸ªå¼‚å¸¸ç‚¹è¯¦æƒ…ã€‘")
                lines.append(f"  æ—¶é—´ï¼š{first_anomaly['time']}")
                lines.append(f"  ä½ç½®ï¼šç¬¬ {first_anomaly['index'] + 1} ä¸ªæ•°æ®ç‚¹")
                lines.append(f"  TÂ²å€¼ï¼š{first_anomaly['T2X_value']:.4f} (é˜ˆå€¼: {thresholds['UCL_T2X']:.4f})")
                lines.append(f"  SPEå€¼ï¼š{first_anomaly['SPEX_value']:.4f} (é˜ˆå€¼: {thresholds['UCL_SPEX']:.4f})")
                
                # TÂ² è´¡çŒ®åº¦åˆ†æ
                if first_anomaly.get('T2X_anomaly') and 'T2X_top_features' in first_anomaly:
                    lines.append("\n  TÂ²å¼‚å¸¸ä¸»è¦è´¡çŒ®ç‰¹å¾ï¼š")
                    for i, (feature, contrib) in enumerate(first_anomaly['T2X_top_features'].items(), 1):
                        lines.append(f"    {i}. {feature}: {contrib:.6f}")
                
                # SPE è´¡çŒ®åº¦åˆ†æ
                if first_anomaly.get('SPEX_anomaly') and 'SPEX_top_features' in first_anomaly:
                    lines.append("\n  SPEå¼‚å¸¸ä¸»è¦è´¡çŒ®ç‰¹å¾ï¼š")
                    for i, (feature, contrib) in enumerate(first_anomaly['SPEX_top_features'].items(), 1):
                        lines.append(f"    {i}. {feature}: {contrib:.6f}")
        
        lines.append("\n" + "=" * 70)
        
        return "\n".join(lines)
    
    def plot_analysis_result(
        self,
        start_time: str,
        end_time: str,
        save_path: Optional[str] = None,
        figsize: Tuple[int, int] = (14, 10)
    ) -> Optional[str]:
        """
        ç»˜åˆ¶åˆ†æç»“æœçš„å¯è§†åŒ–å›¾è¡¨
        
        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            save_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™æ˜¾ç¤ºå›¾è¡¨
            figsize: å›¾è¡¨å¤§å°
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœåªæ˜¯æ˜¾ç¤ºåˆ™è¿”å› None
        """
        try:
            # 1. è·å–æ•°æ®å’Œè®¡ç®—ç»Ÿè®¡é‡
            query_tool = DataQueryTool(data_path=self.data_path)
            query_tool.df['æ—¶é—´'] = pd.to_datetime(query_tool.df['æ—¶é—´'])
            
            start_dt = pd.to_datetime(start_time)
            end_dt = pd.to_datetime(end_time)
            mask = (query_tool.df['æ—¶é—´'] >= start_dt) & (query_tool.df['æ—¶é—´'] <= end_dt)
            data_df = query_tool.df[mask].copy()
            
            if len(data_df) == 0:
                print(f"è­¦å‘Šï¼šåœ¨ {start_time} åˆ° {end_time} èŒƒå›´å†…æœªæ‰¾åˆ°æ•°æ®")
                return None
            
            # æå–ç‰¹å¾æ•°æ®
            feature_cols = [col for col in data_df.columns if col.startswith('feature')]
            feature_cols.sort(key=lambda x: int(x.replace('feature', '')))
            X_data = data_df[feature_cols].values
            
            # æ ‡å‡†åŒ–
            X_scaled = self.pls_tool.scaler_X.transform(X_data)
            
            # è®¡ç®—ç»Ÿè®¡é‡
            T2X, SPEX, E_X = self.pls_tool._compute_pls_stats(X_scaled)
            
            # æ£€æµ‹å¼‚å¸¸
            anomalies_T2X = T2X > self.pls_tool.UCL_T2X
            anomalies_SPEX = SPEX > self.pls_tool.UCL_SPEX
            anomalies_combined = anomalies_T2X | anomalies_SPEX
            
            # 2. åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 1, figsize=figsize)
            fig.suptitle('æŸæµæ³¢åŠ¨ PLS åˆ†æç»“æœ', fontsize=16, fontweight='bold')
            
            time_points = data_df['æ—¶é—´'].values
            
            # ç»˜åˆ¶ TÂ² å›¾
            ax1 = axes[0]
            ax1.plot(time_points, T2X, 'b-', linewidth=1, label='TÂ² ç»Ÿè®¡é‡', alpha=0.7)
            ax1.axhline(y=self.pls_tool.UCL_T2X, color='r', linestyle='--', 
                       linewidth=2, label=f'UCL = {self.pls_tool.UCL_T2X:.2f}')
            
            # æ ‡æ³¨ TÂ² å¼‚å¸¸ç‚¹
            if np.any(anomalies_T2X):
                ax1.scatter(time_points[anomalies_T2X], T2X[anomalies_T2X], 
                           color='red', s=50, marker='o', label='å¼‚å¸¸ç‚¹', zorder=5)
            
            ax1.set_ylabel('TÂ² ç»Ÿè®¡é‡', fontsize=12)
            ax1.set_title('TÂ² ç»Ÿè®¡é‡ç›‘æ§å›¾', fontsize=14, pad=10)
            ax1.legend(loc='upper right')
            ax1.grid(True, alpha=0.3)
            ax1.tick_params(axis='x', rotation=45)
            
            # ç»˜åˆ¶ SPE å›¾
            ax2 = axes[1]
            ax2.plot(time_points, SPEX, 'g-', linewidth=1, label='SPE ç»Ÿè®¡é‡', alpha=0.7)
            ax2.axhline(y=self.pls_tool.UCL_SPEX, color='r', linestyle='--', 
                       linewidth=2, label=f'UCL = {self.pls_tool.UCL_SPEX:.2f}')
            
            # æ ‡æ³¨ SPE å¼‚å¸¸ç‚¹
            if np.any(anomalies_SPEX):
                ax2.scatter(time_points[anomalies_SPEX], SPEX[anomalies_SPEX], 
                           color='red', s=50, marker='o', label='å¼‚å¸¸ç‚¹', zorder=5)
            
            ax2.set_xlabel('æ—¶é—´', fontsize=12)
            ax2.set_ylabel('SPE ç»Ÿè®¡é‡', fontsize=12)
            ax2.set_title('SPE ç»Ÿè®¡é‡ç›‘æ§å›¾', fontsize=14, pad=10)
            ax2.legend(loc='upper right')
            ax2.grid(True, alpha=0.3)
            ax2.tick_params(axis='x', rotation=45)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
            anomaly_count = np.sum(anomalies_combined)
            anomaly_rate = anomaly_count / len(T2X) if len(T2X) > 0 else 0
            info_text = f'æ ·æœ¬æ•°: {len(T2X)}\nå¼‚å¸¸æ•°: {anomaly_count}\nå¼‚å¸¸ç‡: {anomaly_rate:.2%}'
            
            fig.text(0.02, 0.98, info_text, 
                    transform=fig.transFigure,
                    fontsize=10,
                    verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            
            plt.tight_layout(rect=[0, 0, 1, 0.96])
            
            # 3. ä¿å­˜æˆ–æ˜¾ç¤º
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                print(f"å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
                plt.close(fig)
                return save_path
            else:
                plt.show()
                return None
                
        except Exception as e:
            print(f"ç»˜å›¾å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None


# å®šä¹‰å¯è§†åŒ–å·¥å…·çš„å·¥å…·æè¿°ï¼ˆOpenAI Function Callingæ ¼å¼ï¼‰
VISUALIZATION_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "visualize_beam_fluctuation",
            "description": "åˆ†æå¹¶å¯è§†åŒ–æŸæµæ³¢åŠ¨æ•°æ®ã€‚è¯¥å·¥å…·ä¼šæ‰§è¡Œ PLS åˆ†æï¼Œç”Ÿæˆæ˜“è¯»çš„è‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼Œå¹¶ç»˜åˆ¶åŒ…å« TÂ² å’Œ SPE ç»Ÿè®¡é‡çš„å¯è§†åŒ–å›¾è¡¨ã€‚é€‚åˆéœ€è¦å…¨é¢äº†è§£æŸæµçŠ¶æ€å’Œç”ŸæˆæŠ¥å‘Šçš„åœºæ™¯ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "start_time": {
                        "type": "string",
                        "description": "å¼€å§‹æ—¶é—´ï¼Œæ”¯æŒæ ¼å¼ï¼š'YYYY-MM-DD HH:MM:SS' æˆ– 'YYYY-MM-DDTHH:MM:SS'ã€‚ä¾‹å¦‚ï¼š'2025-08-30 17:23:26'"
                    },
                    "end_time": {
                        "type": "string",
                        "description": "ç»“æŸæ—¶é—´ï¼Œæ”¯æŒæ ¼å¼ï¼š'YYYY-MM-DD HH:MM:SS' æˆ– 'YYYY-MM-DDTHH:MM:SS'ã€‚ä¾‹å¦‚ï¼š'2025-08-30 18:23:30'"
                    },
                    "save_path": {
                        "type": "string",
                        "description": "å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œä¾‹å¦‚ 'output/beam_analysis.png'ã€‚å¦‚æœä¸æä¾›ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶åå¹¶ä¿å­˜åˆ° output/ ç›®å½•"
                    },
                    "show_plot": {
                        "type": "boolean",
                        "description": "æ˜¯å¦ç”Ÿæˆå›¾è¡¨ï¼Œé»˜è®¤ä¸º True"
                    }
                },
                "required": ["start_time", "end_time"]
            }
        }
    }
]


# å®šä¹‰ä¾› LLM è°ƒç”¨çš„å·¥å…·å‡½æ•°
def visualize_beam_fluctuation(
    start_time: str, 
    end_time: str,
    save_path: Optional[str] = None,
    show_plot: bool = True
) -> Dict[str, Any]:
    """
    åˆ†æå¹¶å¯è§†åŒ–æŸæµæ³¢åŠ¨æ•°æ®
    
    è¯¥å‡½æ•°ä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
    1. è°ƒç”¨ PLS æ¨¡å‹åˆ†ææŒ‡å®šæ—¶é—´èŒƒå›´çš„æŸæµæ•°æ®
    2. å°†åˆ†æç»“æœè½¬æ¢ä¸ºæ˜“è¯»çš„è‡ªç„¶è¯­è¨€æè¿°
    3. ç”ŸæˆåŒ…å« TÂ² å’Œ SPE ç»Ÿè®¡é‡çš„å¯è§†åŒ–å›¾è¡¨
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼å¦‚ "2025-08-30 17:23:26"
        end_time: ç»“æŸæ—¶é—´ï¼Œæ ¼å¼å¦‚ "2025-08-30 18:23:30"
        save_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œä¾‹å¦‚ "output/beam_analysis.png"
                  å¦‚æœä¸æä¾›ï¼Œå›¾è¡¨å°†æ˜¾ç¤ºåœ¨å±å¹•ä¸Š
        show_plot: æ˜¯å¦ç”Ÿæˆå›¾è¡¨ï¼Œé»˜è®¤ä¸º True
    
    Returns:
        åŒ…å«ä»¥ä¸‹å†…å®¹çš„å­—å…¸ï¼š
        - success: æ˜¯å¦æˆåŠŸ
        - text_report: è‡ªç„¶è¯­è¨€æ ¼å¼çš„åˆ†ææŠ¥å‘Š
        - plot_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¿å­˜äº†çš„è¯ï¼‰
        - raw_result: åŸå§‹åˆ†æç»“æœ
    """
    try:
        # 1. æ‰§è¡Œ PLS åˆ†æ
        tool = PLSAnalysisTool()
        analysis_result = tool.analyze_fluctuation(start_time, end_time)
        
        if not analysis_result.get('success', False):
            return {
                "success": False,
                "error": analysis_result.get('error', 'æœªçŸ¥é”™è¯¯'),
                "message": analysis_result.get('message', 'åˆ†æå¤±è´¥'),
                "text_report": None,
                "plot_path": None,
                "raw_result": analysis_result
            }
        
        # 2. ç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Š
        viz_tool = BeamVisualizationTool()
        text_report = viz_tool.format_analysis_result(analysis_result)
        
        # 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        plot_path = None
        if show_plot:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šä¿å­˜è·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª
            if save_path is None:
                # åˆ›å»º output ç›®å½•
                output_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'output')
                os.makedirs(output_dir, exist_ok=True)
                
                # ç”Ÿæˆæ–‡ä»¶å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = os.path.join(output_dir, f'beam_analysis_{timestamp}.png')
            
            plot_path = viz_tool.plot_analysis_result(start_time, end_time, save_path=save_path)
        
        return {
            "success": True,
            "text_report": text_report,
            "plot_path": plot_path,
            "raw_result": analysis_result,
            "message": "åˆ†æå’Œå¯è§†åŒ–å®Œæˆ"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"å¯è§†åŒ–åˆ†æå¤±è´¥: {str(e)}",
            "text_report": None,
            "plot_path": None,
            "raw_result": None
        }


# å¯è§†åŒ–å·¥å…·å‡½æ•°æ˜ å°„
VISUALIZATION_TOOL_FUNCTIONS = {
    "visualize_beam_fluctuation": visualize_beam_fluctuation
}

